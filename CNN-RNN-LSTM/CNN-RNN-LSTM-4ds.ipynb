{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbd8ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense # type: ignore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ae9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d2f67ab",
   "metadata": {},
   "source": [
    "Creación de dataframes a partir de datasets:\n",
    "Datasets utilizados:\n",
    "RAVESS\n",
    "SAVEE\n",
    "TESS\n",
    "CREMA-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0f5d3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming download from 94371840 bytes (354200194 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/ejlok1/toronto-emotional-speech-set-tess?dataset_version_number=1 (94371840/448572034) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 428M/428M [00:39<00:00, 8.94MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/ejlok1/surrey-audiovisual-expressed-emotion-savee?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107M/107M [00:19<00:00, 5.82MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "TESS = kagglehub.dataset_download(\"ejlok1/toronto-emotional-speech-set-tess\")\n",
    "CREMA = kagglehub.dataset_download(\"ejlok1/cremad\")\n",
    "RAV = kagglehub.dataset_download(\"uwrfkaggler/ravdess-emotional-speech-audio\")\n",
    "SAVEE = kagglehub.dataset_download(\"ejlok1/surrey-audiovisual-expressed-emotion-savee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "761788ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "male_neutral       144\n",
       "female_neutral     144\n",
       "male_disgust        96\n",
       "male_angry          96\n",
       "male_sad            96\n",
       "male_surprise       96\n",
       "male_fear           96\n",
       "male_happy          96\n",
       "female_angry        96\n",
       "female_fear         96\n",
       "female_surprise     96\n",
       "female_sad          96\n",
       "female_happy        96\n",
       "female_disgust      96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = Path(RAV) / 'audio_speech_actors_01-24'\n",
    "dir_list = os.listdir(dataset_dir)\n",
    "dir_list.sort()\n",
    "\n",
    "emotion = []\n",
    "gender = []\n",
    "path = []\n",
    "for i in dir_list:\n",
    "    actor_path = dataset_dir / i # Path to the current actor's directory\n",
    "    if actor_path.is_dir(): # Ensure it's a directory\n",
    "        fname = os.listdir(actor_path)\n",
    "        for f in fname:\n",
    "            if f.endswith('.wav'): # Process only .wav files\n",
    "                # Filenames are like '03-01-04-01-02-01-01.wav'\n",
    "                parts_without_ext = f.split('.')[0]\n",
    "                part = parts_without_ext.split('-')\n",
    "                if len(part) >= 7: # Ensure we have enough parts for indices 2 and 6\n",
    "                    emotion.append(int(part[2])) # Emotion index is 2\n",
    "                    temp = int(part[6]) # Actor number for gender is 6\n",
    "                    if temp % 2 == 0:\n",
    "                        temp = \"female\"\n",
    "                    else:\n",
    "                        temp = \"male\"\n",
    "                    gender.append(temp)\n",
    "                    path.append(actor_path / f)\n",
    "\n",
    "RAV_df = pd.DataFrame(emotion)\n",
    "RAV_df = RAV_df.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "RAV_df = pd.concat([pd.DataFrame(gender),RAV_df],axis=1)\n",
    "RAV_df.columns = ['gender','emotion']\n",
    "RAV_df['labels'] =RAV_df.gender + '_' + RAV_df.emotion\n",
    "RAV_df['source'] = 'RAVDESS'\n",
    "RAV_df = pd.concat([RAV_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "RAV_df = RAV_df.drop(['gender', 'emotion'], axis=1)\n",
    "RAV_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "317c5b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "male_neutral     120\n",
       "male_disgust      60\n",
       "male_angry        60\n",
       "male_fear         60\n",
       "male_happy        60\n",
       "male_sad          60\n",
       "male_surprise     60\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = Path(SAVEE)/'ALL'\n",
    "dir_list = os.listdir(dataset_dir)\n",
    "dir_list.sort()\n",
    "\n",
    "emotion = []\n",
    "path = []\n",
    "\n",
    "for i in dir_list:\n",
    "    if i[-8:-6]=='_a':\n",
    "        emotion.append('male_angry')\n",
    "    elif i[-8:-6]=='_d':\n",
    "        emotion.append('male_disgust')\n",
    "    elif i[-8:-6]=='_f':\n",
    "        emotion.append('male_fear')\n",
    "    elif i[-8:-6]=='_h':\n",
    "        emotion.append('male_happy')\n",
    "    elif i[-8:-6]=='_n':\n",
    "        emotion.append('male_neutral')\n",
    "    elif i[-8:-6]=='sa':\n",
    "        emotion.append('male_sad')\n",
    "    elif i[-8:-6]=='su':\n",
    "        emotion.append('male_surprise')\n",
    "    else:\n",
    "        emotion.append('male_error')\n",
    "    path.append(str(dataset_dir / i)) # Convert Path object to string for consistency with previous use of SAVEE + i\n",
    "\n",
    "SAVEE_df = pd.DataFrame(emotion, columns = ['labels'])\n",
    "SAVEE_df['source'] = 'SAVEE'\n",
    "SAVEE_df = pd.concat([SAVEE_df, pd.DataFrame(path, columns = ['path'])], axis = 1)\n",
    "SAVEE_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57ba6f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "female_fear        400\n",
       "female_surprise    400\n",
       "female_sad         400\n",
       "female_angry       400\n",
       "female_disgust     400\n",
       "female_happy       400\n",
       "female_neutral     400\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TESS_data_base_path = Path(TESS) / 'TESS Toronto emotional speech set data'\n",
    "\n",
    "dir_list = os.listdir(TESS_data_base_path)\n",
    "dir_list.sort()\n",
    "\n",
    "path = []\n",
    "emotion = []\n",
    "\n",
    "for i in dir_list:\n",
    "    current_emotion_dir = TESS_data_base_path / i\n",
    "    if current_emotion_dir.is_dir():\n",
    "        fname = os.listdir(current_emotion_dir)\n",
    "        for f in fname:\n",
    "            if i == 'OAF_angry' or i == 'YAF_angry':\n",
    "                emotion.append('female_angry')\n",
    "            elif i == 'OAF_disgust' or i == 'YAF_disgust':\n",
    "                emotion.append('female_disgust')\n",
    "            elif i == 'OAF_Fear' or i == 'YAF_fear':\n",
    "                emotion.append('female_fear')\n",
    "            elif i == 'OAF_happy' or i == 'YAF_happy':\n",
    "                emotion.append('female_happy')\n",
    "            elif i == 'OAF_neutral' or i == 'YAF_neutral':\n",
    "                emotion.append('female_neutral')\n",
    "            elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':\n",
    "                emotion.append('female_surprise')\n",
    "            elif i == 'OAF_Sad' or i == 'YAF_sad':\n",
    "                emotion.append('female_sad')\n",
    "            else:\n",
    "                emotion.append('Unknown')\n",
    "            path.append(str(current_emotion_dir / f))\n",
    "\n",
    "TESS_df = pd.DataFrame(emotion, columns = ['labels'])\n",
    "TESS_df['source'] = 'TESS'\n",
    "TESS_df = pd.concat([TESS_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "TESS_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01bfbf3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "male_angry        671\n",
       "male_disgust      671\n",
       "male_fear         671\n",
       "male_happy        671\n",
       "male_sad          671\n",
       "female_angry      600\n",
       "female_disgust    600\n",
       "female_fear       600\n",
       "female_sad        600\n",
       "female_happy      600\n",
       "male_neutral      575\n",
       "female_neutral    512\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "crema_data_path = Path(CREMA) / 'AudioWAV'\n",
    "dir_list = os.listdir(crema_data_path)\n",
    "dir_list.sort()\n",
    "\n",
    "gender = []\n",
    "emotion = []\n",
    "path = []\n",
    "female = [1002,1003,1004,1006,1007,1008,1009,1010,1012,1013,1018,1020,1021,1024,1025,1028,1029,1030,1037,1043,1046,1047,1049,\n",
    "          1052,1053,1054,1055,1056,1058,1060,1061,1063,1072,1073,1074,1075,1076,1078,1079,1082,1084,1089,1091]\n",
    "\n",
    "for i in dir_list:\n",
    "    part = i.split('_')\n",
    "    if int(part[0]) in female:\n",
    "        temp = 'female'\n",
    "    else:\n",
    "        temp = 'male'\n",
    "    gender.append(temp)\n",
    "    if part[2] == 'SAD' and temp == 'male':\n",
    "        emotion.append('male_sad')\n",
    "    elif part[2] == 'ANG' and temp == 'male':\n",
    "        emotion.append('male_angry')\n",
    "    elif part[2] == 'DIS' and temp == 'male':\n",
    "        emotion.append('male_disgust')\n",
    "    elif part[2] == 'FEA' and temp == 'male':\n",
    "        emotion.append('male_fear')\n",
    "    elif part[2] == 'HAP' and temp == 'male':\n",
    "        emotion.append('male_happy')\n",
    "    elif part[2] == 'NEU' and temp == 'male':\n",
    "        emotion.append('male_neutral')\n",
    "    elif part[2] == 'SAD' and temp == 'female':\n",
    "        emotion.append('female_sad')\n",
    "    elif part[2] == 'ANG' and temp == 'female':\n",
    "        emotion.append('female_angry')\n",
    "    elif part[2] == 'DIS' and temp == 'female':\n",
    "        emotion.append('female_disgust')\n",
    "    elif part[2] == 'FEA' and temp == 'female':\n",
    "        emotion.append('female_fear')\n",
    "    elif part[2] == 'HAP' and temp == 'female':\n",
    "        emotion.append('female_happy')\n",
    "    elif part[2] == 'NEU' and temp == 'female':\n",
    "        emotion.append('female_neutral')\n",
    "    else:\n",
    "        emotion.append('Unknown')\n",
    "    path.append(str(crema_data_path / i))\n",
    "\n",
    "CREMA_df = pd.DataFrame(emotion, columns = ['labels'])\n",
    "CREMA_df['source'] = 'CREMA'\n",
    "CREMA_df = pd.concat([CREMA_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "CREMA_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957848e4",
   "metadata": {},
   "source": [
    "Distribución de emociones en el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65128e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries in the combined dataset: 12162\n",
      "\n",
      "Label distribution by source:\n",
      "source   labels         \n",
      "CREMA    male_angry         671\n",
      "         male_disgust       671\n",
      "         male_fear          671\n",
      "         male_happy         671\n",
      "         male_sad           671\n",
      "         female_angry       600\n",
      "         female_disgust     600\n",
      "         female_fear        600\n",
      "         female_happy       600\n",
      "         female_sad         600\n",
      "         male_neutral       575\n",
      "         female_neutral     512\n",
      "RAVDESS  female_neutral     144\n",
      "         male_neutral       144\n",
      "         female_angry        96\n",
      "         female_disgust      96\n",
      "         female_fear         96\n",
      "         female_happy        96\n",
      "         female_sad          96\n",
      "         female_surprise     96\n",
      "         male_angry          96\n",
      "         male_disgust        96\n",
      "         male_fear           96\n",
      "         male_happy          96\n",
      "         male_sad            96\n",
      "         male_surprise       96\n",
      "SAVEE    male_neutral       120\n",
      "         male_angry          60\n",
      "         male_disgust        60\n",
      "         male_fear           60\n",
      "         male_happy          60\n",
      "         male_sad            60\n",
      "         male_surprise       60\n",
      "TESS     female_angry       400\n",
      "         female_disgust     400\n",
      "         female_fear        400\n",
      "         female_happy       400\n",
      "         female_neutral     400\n",
      "         female_sad         400\n",
      "         female_surprise    400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([RAV_df, SAVEE_df, TESS_df, CREMA_df], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"Total number of entries in the combined dataset: {len(combined_df)}\")\n",
    "print(\"\\nLabel distribution by source:\")\n",
    "print(combined_df.groupby('source')['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e396b54e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Get the value counts of the labels in combined_df\u001b[39;00m\n\u001b[32m      5\u001b[39m label_counts = combined_df[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m].value_counts().reset_index()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get the value counts of the labels in combined_df\n",
    "label_counts = combined_df['labels'].value_counts().reset_index()\n",
    "label_counts.columns = ['labels', 'count']\n",
    "\n",
    "# Sort the labels for better visualization if needed, or keep as is\n",
    "label_counts = label_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Create a bar plot, addressing the FutureWarning\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='count', y='labels', data=label_counts, palette='viridis', hue='labels', legend=False)\n",
    "plt.title('Distribution of Labels in Combined Dataset')\n",
    "plt.xlabel('Number of Entries')\n",
    "plt.ylabel('Label (Gender_Emotion)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455e340b",
   "metadata": {},
   "source": [
    "Distribución de muestras dentro de cada emoción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed489550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the emotion from the 'labels' column\n",
    "# This assumes labels are in 'gender_emotion' format\n",
    "combined_df['emotion_only'] = combined_df['labels'].apply(lambda x: x.split('_')[1] if '_' in x else x)\n",
    "\n",
    "# Get the value counts of the emotions\n",
    "emotion_counts = combined_df['emotion_only'].value_counts().reset_index()\n",
    "emotion_counts.columns = ['emotion', 'count']\n",
    "\n",
    "# Sort the emotions for better visualization\n",
    "emotion_counts = emotion_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Create a bar plot for emotion distribution\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.barplot(x='count', y='emotion', data=emotion_counts, palette='viridis', hue='emotion', legend=False)\n",
    "plt.title('Total Distribution of Samples per Emotion (Gender Discarded)')\n",
    "plt.xlabel('Number of Samples')\n",
    "plt.ylabel('Emotion')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Drop the temporary 'emotion_only' column\n",
    "combined_df = combined_df.drop(columns=['emotion_only'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975dd16",
   "metadata": {},
   "source": [
    "Creación del entorno para ejecutar luego el modelo en un script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Get all unique labels from the combined_df\n",
    "unique_labels = combined_df['labels'].unique()\n",
    "\n",
    "# Create EMOTION_MAP\n",
    "EMOTION_MAP = {label: i for i, label in enumerate(unique_labels)}\n",
    "n_emotions = len(EMOTION_MAP)\n",
    "\n",
    "print(\"EMOTION_MAP created:\")\n",
    "print(EMOTION_MAP)\n",
    "print(f\"Number of emotions (n_emotions): {n_emotions}\")\n",
    "\n",
    "# Ensure output_dir exists for saving class names\n",
    "output_dir = './model_metadata'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save EMOTION_MAP to a pickle file\n",
    "with open(os.path.join(output_dir, 'class_names.pkl'), 'wb') as f:\n",
    "    pickle.dump(EMOTION_MAP, f)\n",
    "\n",
    "print(\"Lista de clases guardada como 'class_names.pkl' in model_metadata folder\")\n",
    "#Se guardarás mas metadatos en la función extract_mfccs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e9a4fd",
   "metadata": {},
   "source": [
    "Constantes de preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f3de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- CONSTANTES DE PREPROCESAMIENTO ---\n",
    "# Frecuencia de muestreo (Sample Rate) - CONFIRMADO: 16kHz\n",
    "SR = 16000\n",
    "# Longitud del paso de ventana (Hop Length) ~10ms - CONFIRMADO: 160\n",
    "HOP_LENGTH = 160\n",
    "# Duración fija del segmento de audio (en segundos)\n",
    "DURATION = 3.0\n",
    "# Número total de características (13 MFCCs + Delta + Delta-Delta)\n",
    "N_MFCC_BASE = 13\n",
    "N_FEATURES = N_MFCC_BASE * 3\n",
    "# Muestras totales por segmento (3 segundos * 16000 SR)\n",
    "SAMPLES_PER_SEGMENT = SR * DURATION\n",
    "# Número de pasos de tiempo (timesteps) para la RNN (ajustado por hop_length y SR)\n",
    "N_TIMESTEPS = 297\n",
    "SEED = 42\n",
    "\n",
    "# Resumen de la configuración\n",
    "print(\"--- Configuración de Preprocesamiento ---\")\n",
    "print(f\"Frecuencia de Muestreo (SR): {SR} Hz\")\n",
    "print(f\"Características por Timestep: {N_FEATURES} (13 MFCCs + Deltas)\")\n",
    "print(f\"Timesteps para la RNN: {N_TIMESTEPS} (~3 segundos)\")\n",
    "print(f\"Clases de Emoción detectadas: {n_emotions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddefda4",
   "metadata": {},
   "source": [
    "Funciones de extracción y preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ccc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extracción de MFCCs con duración estandarizada\n",
    "def extract_mfccs(audio_path: str) -> np.ndarray:\n",
    "    \"\"\"Carga audio, estandariza duración y extrae MFCCs (39).\"\"\"\n",
    "    longitud_en_muestras = int(DURATION * SR)\n",
    "    y, sr = librosa.load(audio_path, sr=SR)\n",
    "    y_estandarizado = librosa.util.fix_length(y, size=longitud_en_muestras)\n",
    "    mfccs = librosa.feature.mfcc(y=y_estandarizado, sr=SR, n_mfcc=N_MFCC_BASE, hop_length=HOP_LENGTH)\n",
    "    mfccs_delta = librosa.feature.delta(mfccs)\n",
    "    mfccs_delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "    mfccs_completos = np.concatenate((mfccs, mfccs_delta, mfccs_delta2), axis=0)\n",
    "    mfccs_fijo = librosa.util.fix_length(mfccs_completos, size=N_TIMESTEPS, axis=1)\n",
    "    return mfccs_fijo.T \n",
    "\n",
    "# Normalización Z-Score Global\n",
    "def z_score_normalize(X_train: np.ndarray, X_val: np.ndarray, X_test: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Calcula Z-Score solo con los datos de entrenamiento y lo aplica a todos.\"\"\"\n",
    "    X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
    "    GLOBAL_MEAN = np.mean(X_train_flat, axis=0)\n",
    "    GLOBAL_STD = np.std(X_train_flat, axis=0)\n",
    "    GLOBAL_STD[GLOBAL_STD == 0] = 1e-6 \n",
    "\n",
    "    # Opcional: Crear un directorio para los metadatos si no existe\n",
    "    output_dir = './model_metadata'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Guardar la media en un archivo .npy\n",
    "    np.save(os.path.join(output_dir, 'global_mean.npy'), GLOBAL_MEAN)\n",
    "    \n",
    "    # Guardar la desviación estándar en un archivo .npy\n",
    "    np.save(os.path.join(output_dir, 'global_std.npy'), GLOBAL_STD)\n",
    "    \n",
    "    print(f\"\\nMetadatos de normalización guardados en: {output_dir}\")\n",
    "\n",
    "    X_train_norm = (X_train - GLOBAL_MEAN) / GLOBAL_STD\n",
    "    X_val_norm = (X_val - GLOBAL_MEAN) / GLOBAL_STD\n",
    "    X_test_norm = (X_test - GLOBAL_MEAN) / GLOBAL_STD\n",
    "    \n",
    "    return X_train_norm, X_val_norm, X_test_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d2e35",
   "metadata": {},
   "source": [
    "Ejecución del preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb47833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3.2. Carga, Extracción de MFCCs y Etiquetado desde combined_df\n",
    "X_data = []\n",
    "y_labels = []\n",
    "\n",
    "print(\"Iniciando extracción de MFCCs y etiquetado desde combined_df...\")\n",
    "\n",
    "for index, row in combined_df.iterrows():\n",
    "    audio_path = row['path']\n",
    "    label_str = row['labels']\n",
    "\n",
    "    try:\n",
    "        mfccs_matrix = extract_mfccs(audio_path)\n",
    "        if mfccs_matrix.shape == (N_TIMESTEPS, N_FEATURES):\n",
    "            X_data.append(mfccs_matrix)\n",
    "            y_labels.append(EMOTION_MAP[label_str])\n",
    "        else:\n",
    "            print(f\"Alerta: {audio_path} tiene forma {mfccs_matrix.shape}, se ignora.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar {audio_path}: {e}\")\n",
    "\n",
    "X_data = np.array(X_data)\n",
    "y_labels = np.array(y_labels)\n",
    "\n",
    "# The class_names should represent the integer labels, which are the values of EMOTION_MAP\n",
    "class_names = sorted(list(EMOTION_MAP.values()))\n",
    "\n",
    "print(\"\\n--- Resumen de Datos ---\")\n",
    "print(f\"Número total de muestras cargadas: {X_data.shape[0]}\")\n",
    "print(f\"Clases: {class_names}\")\n",
    "\n",
    "# 3.3. División de datos (Train, Val, Test)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_data, y_labels, test_size=0.1, random_state=SEED, stratify=y_labels\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=(0.1/0.9), random_state=SEED, stratify=y_train_val\n",
    ")\n",
    "\n",
    "# 3.4. Normalización Z-Score Global\n",
    "X_train_norm, X_val_norm, X_test_norm = z_score_normalize(X_train, X_val, X_test)\n",
    "\n",
    "print(\"\\n--- ¡PREPROCESAMIENTO COMPLETO! ---\")\n",
    "print(f\"X_train_norm shape (Listo para RNN): {X_train_norm.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val_norm shape: {X_val_norm.shape}\")\n",
    "print(f\"X_test_norm shape: {X_test_norm.shape}\")\n",
    "print(f\"Número de clases: {len(class_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cab4cbf",
   "metadata": {},
   "source": [
    "Creación y Train de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7aa20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# --- 1. Preparación Final de Etiquetas ---\n",
    "# Las etiquetas 'y' están en formato entero (0 a 7), lo cual es ideal para Sparse Categorical Crossentropy,\n",
    "# pero Keras funciona bien si están en one-hot para ciertos flujos o si se usa Categorical Crossentropy.\n",
    "# Mantendremos el formato entero y usaremos 'sparse_categorical_crossentropy' por simplicidad.\n",
    "\n",
    "# --- 2. Definir Parámetros de Entrenamiento ---\n",
    "# Parámetros definidos en el preprocesamiento\n",
    "N_TIMESTEPS = X_train_norm.shape[1] # 297\n",
    "N_FEATURES = X_train_norm.shape[2]  # 39\n",
    "NUM_CLASSES = len(class_names)      # 14\n",
    "BATCH_SIZE = 64 # Mantener el batch size ligero para la RAM\n",
    "EPOCHS = 200\n",
    "\n",
    "# --- 3. Definir el Modelo (ARQUITECTURA HÍBRIDA CONV1D + BIDIRECTIONAL LSTM) ---\n",
    "\n",
    "# Input shape para la capa: (Timesteps, Características)\n",
    "input_shape = (N_TIMESTEPS, N_FEATURES)\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Capa 1: Conv1D para extracción de características locales\n",
    "model.add(layers.Conv1D(\n",
    "    filters=64,\n",
    "    kernel_size=5, # Common kernel size, can be tuned\n",
    "    activation='relu',\n",
    "    input_shape=input_shape,\n",
    "    padding='same' # Keep the sequence length\n",
    "))\n",
    "model.add(layers.BatchNormalization()) # Stabilize training\n",
    "model.add(layers.MaxPooling1D(pool_size=2)) # Reduce sequence length, helps LSTM process longer sequences effectively\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Capa 2: Bidirectional LSTM para captura de contexto bidireccional\n",
    "model.add(layers.Bidirectional(layers.LSTM(\n",
    "    units=64,\n",
    "    return_sequences=True, # Pass full sequence to next LSTM layer\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    ")))\n",
    "model.add(layers.BatchNormalization()) # Stabilize training\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Capa 3: Segunda Bidirectional LSTM\n",
    "model.add(layers.Bidirectional(layers.LSTM(\n",
    "    units=32,\n",
    "    return_sequences=False, # Only return the last output for classification\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    ")))\n",
    "model.add(layers.BatchNormalization()) # Stabilize training\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Capa 4: Densa de clasificación\n",
    "model.add(layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(layers.BatchNormalization()) # Stabilize training\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "# --- 4. Compilar el Modelo ---\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    # Usamos sparse_categorical_crossentropy porque y_train es un array de enteros (0, 1, 2, ...)\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Early stopping (mejorado)\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20, # Aumentar la paciencia para dar más oportunidad a la red para converger\n",
    "    restore_best_weights=True\n",
    ")\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5, # Reducir el LR a la mitad\n",
    "    patience=7, # Si val_loss no mejora en 7 épocas, reduce LR\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint_filepath = './checkpoints/modelo_ep_{epoch:02d}.keras'\n",
    "\n",
    "# 1. Configurar el callback\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',          # Monitorea la precisión de validación\n",
    "    verbose=1,                      # Muestra mensajes de guardado\n",
    "    save_best_only=False,           # Guarda todos los puntos de control, no solo el mejor\n",
    "    save_weights_only=False,        # Guarda el modelo completo (arquitectura + pesos)\n",
    "    mode='max',                     # Maximiza la métrica (val_accuracy)\n",
    "    save_freq= 5 + 'epoch'          # Guarda cada época, para que val_accuracy esté disponible\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# --- 5. Entrenar el Modelo ---\n",
    "print(\"\\n--- Iniciando entrenamiento del modelo híbrido ---\")\n",
    "\n",
    "# Entrenar directamente sobre los arrays de NumPy ya preprocesados\n",
    "history = model.fit(\n",
    "    X_train_norm,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val_norm, y_val),\n",
    "    callbacks=[early_stop, lr_scheduler, model_checkpoint_callback],\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"\\n--- Entrenamiento completado ---\")\n",
    "\n",
    "# --- 6. Evaluación y Métricas ---\n",
    "\n",
    "# Obtener datos de la historia\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "actual_epochs = len(acc)\n",
    "epochs_range = range(actual_epochs)\n",
    "\n",
    "# Evaluar en el conjunto de prueba\n",
    "print(\"\\n--- Evaluando en conjunto de prueba ---\")\n",
    "test_loss, test_acc = model.evaluate(X_test_norm, y_test, verbose=0)\n",
    "\n",
    "# Predicciones para métricas detalladas\n",
    "test_predictions = model.predict(X_test_norm)\n",
    "test_predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Calcular métricas de clasificación (Precision, Recall, F1-score)\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(\n",
    "    y_test,\n",
    "    test_predicted_labels,\n",
    "    average='weighted',\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "print(f\"\\nPérdida en Test: {test_loss:.4f}\")\n",
    "print(f\"Precisión en Test: {test_acc*100:.2f}%\")\n",
    "print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "print(f\"F1-score (Weighted): {f1_score:.4f}\")\n",
    "\n",
    "\n",
    "# --- 7. Visualización de Resultados ---\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Precisión de Entrenamiento')\n",
    "plt.plot(epochs_range, val_acc, label='Precisión de Validación')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Precisión de Entrenamiento y Validación')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Pérdida de Entrenamiento')\n",
    "plt.plot(epochs_range, val_loss, label='Pérdida de Validación')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Pérdida de Entrenamiento y Validación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce32d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('RNN-LSTM-4ds.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
